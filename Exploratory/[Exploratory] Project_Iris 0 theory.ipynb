{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70068193",
   "metadata": {},
   "source": [
    "# 2. Iris의 세 가지 품종, 분류해볼 수 있겠어요?\n",
    "- scikit-learn을 활용\n",
    "    - 머신러닝, 지도학습의 분류 모델을 학습시키고 예측 시키기\n",
    "- 모델의 성능을 평가하는 지표의 종류 이해, 활용, 확인\n",
    "- Decision Tree, XGBoost, RandomForest, 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dda960",
   "metadata": {},
   "source": [
    "## 1) 붓꽃 분류 문제\n",
    "- petal: 꽃잎, sepal: 꽃받침\n",
    "- 붓꽃의 세 가지 종류: setosa, versicolor, virginica\n",
    "- 머신러닝 기법 활용하여 붓꽃 분류하기\n",
    "\n",
    "#### - 세 가지의 붓꽃은 모두 꽃잎과 꽃받침의 크기가 조금씩 다른데, 머신러닝으로 분류가 가능할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adfc75",
   "metadata": {},
   "source": [
    "### (1) 붓꽃 분류, 어떤 데이터로 할 건데?\n",
    "- 사이킷런(scikit-learn) 에 내장되어 있는 데이터 : https://scikit-learn.org/stable/datasets.html\n",
    "- 간단하고 작은 데이터셋 Toy datasets:  boston, iris, diabetes, digits, linnerud, wine, breast cancer의 7가지 데이터셋\n",
    "- 비교적 복잡하고 현실 세계를 반영한 Real world datasets:  olivetti faces, 20newsgroups, covtype, california housing 등 총 9가지 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fdd95",
   "metadata": {},
   "source": [
    "- 이 중 Toy datasets의 iris 데이터셋을 사용할 것!\n",
    "    - 공식 문서에 따르면, 이 데이터셋에는 총 150개의 데이터가 있고, 각 데이터에는 4개의 정보가 담겨있으며, Iris의 세 가지 품종, 분류해볼 수 있다. \n",
    "    - sepal, petal 각각의 길이와 폭, 총 네 가지의 정보이다.\n",
    "    - 또한 카테고리를 나타내는 클래스는 setosa, versicolour, virginica 세 가지이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8552d8",
   "metadata": {},
   "source": [
    "### 데이터셋 다루기 전 주의:\n",
    "데이터셋의 정보를 먼저 확인하는 것이 중요하다. 데이터를 얼마나 이해하고 있느냐는 그 데이터를 활용한 결과와 성능에 중대한 요소가 되기 때문이다. 데이터셋이 담고 있는 정보를 먼저 잘 확인하고 시작해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d188b8",
   "metadata": {},
   "source": [
    "## 2) 데이터 준비, 그리고 자세히 살펴보기는 기본!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1064eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(type(dir(iris))) # dir()는 객체가 어떤 변수와 매서드를 가지고 있는지 나열함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def9b7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어떤 정보가 있나?\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721b5393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# 가장 중요한 데이터를 변수에 저장하고 크기를 확인하자.\n",
    "iris_data = iris.data\n",
    "print(iris_data.shape) \n",
    "#shape는 배열의 형상정보를 출력, 150개의 데이터가 4개의 정보를 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7acc18b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플로 하나만 확인\n",
    "iris_data[0]\n",
    "# 순서대로 sepal length , sepal width , petal length , petal width의 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90119c1",
   "metadata": {},
   "source": [
    "- 우리의 문제는 꽃잎과 꽃받침의 길이가 주어지는 경우 그 꽃은 세 가지의 붓꽃 품종 중 어떤 것인지를 맞추는 것(setosa, versicolor, virginica 세 가지 중 붓꽃의 종류가 무엇인지 맞추고자 함)이므로,\n",
    "-  머신러닝 모델에게 꽃잎, 꽃받침의 길이와 폭 정보를 입력했을 때 붓꽃의 품종을 출력하도록 학습을 시켜야 한다.\n",
    "\n",
    "\n",
    "- 머신러닝 모델이 출력해야 하는 정답을 **라벨(label)**, 또는 **타겟(target)** 이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9425fb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_label = iris.target\n",
    "print(iris_label.shape) # 총 150개의 데이터\n",
    "iris_label # 각 값은 0, 1, 또는 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a96da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨의 이름\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71dd0de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋의 설명\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b190c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4개의 각 feature\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84059392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\py3_7_6\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 파일이 저장된 경로\n",
    "iris.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94d1aa",
   "metadata": {},
   "source": [
    "# 2. 첫번째 머신러닝 실습_Iris 간단하고도 빠르게!\n",
    "## 1) 머신러닝 모델을 학습시키기 위한 문제지와 정답지 준비\n",
    "- pandas: \n",
    "    -  파이썬에서 표 형태로 이루어진 2차원 배열 데이터를 다루는 데에 가장 많이 쓰이는 도구\n",
    "    -  표 데이터를 활용해서 데이터 분석 또는 대형 데이터의 여러 통계량을 다루기에도 최적화가 되어있음\n",
    "    \n",
    "    \n",
    "- iris 데이터 또한 행과 열이 있는 2차원 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f7ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea937e95",
   "metadata": {},
   "source": [
    "#### - 붓꽃 데이터셋을 DataFrame  자료형으로 변환하기\n",
    "- __주의:  feature, label, target__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98133d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  data 에는 iris_data 를 넣어주고, 각 컬럼에는 feature_names 로 이름을 붙인다.\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a4a466a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 데이터도 label 컬럼으로 추가한다.\n",
    "iris_df[\"label\"] = iris.target\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18454d25",
   "metadata": {},
   "source": [
    "##### 정답 데이터가 있는 label 컬럼을 제외한 나머지 4개의 feature 데이터들은 머신러닝 모델이 풀어야 하는 문제지다.\n",
    "\n",
    "- 문제지 : 머신러닝 모델에게 입력되는 데이터(feature). 변수 이름으로는 __X__ (대문자)\n",
    "- 정답지 : 머신러닝 모델이 맞추어야 하는 데이터(label 또는 target). 변수 이름으로는 __y__ (소문자)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658acf7",
   "metadata": {},
   "source": [
    "#### - 데이터셋 분리: train_test_split () 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a2fe0",
   "metadata": {},
   "source": [
    "머신러닝 모델을 학습시키려면, __학습에 사용하는 training dataset__ 과 __모델의 성능을 평가하는 데 사용하는 test dataset__ 으로 데이터셋을 나누는 작업이 필요하다.\n",
    "\n",
    "\n",
    "우리에게는 150개의 데이터가 있지만, 이 150개를 모두 학습시키는 데에 사용해버리면 학습이 완료된 모델의 성능을 공정하게 평가할 수 없기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dc61066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  120 , X_test 개수:  30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 4개의 feature 데이터만 있는 X, lable 데이터만 있는 y으로 설정하고\n",
    "# X에는 데이터셋을 머신러닝 모델에 입력\n",
    "# 그에 따라 모델이 내뱉는 품종 예측 결과를 정답인 y와 비교하며 학습 시킬 것\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, # 문제지\n",
    "                                                    iris_label, # 정답값\n",
    "                                                    test_size=0.2, # 8:2 비율\n",
    "                                                    random_state=7) \n",
    "\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7c0b3",
   "metadata": {},
   "source": [
    "- random_state란?\n",
    "    - train 데이터와 test 데이터를 분리(split)하는데 적용되는 랜덤성을 결정\n",
    "    - 데이터를 분리할 때 랜덤으로 섞는 과정이 필요하고 그 역할을 함\n",
    "    - 아무리 랜덤이라고 해도 특정 로직에 따라 결정되는 랜덤이기 때문에 완벽한 랜덤이라고 할 수 없음\n",
    "    - 같은 의미로 random_seed도 있음. 내가 실험한 결과를 다른 사람의 컴퓨터에서도 재현가능(reproducible) 하게 하려면 같은 랜덤시드가 필요할 때가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2471080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (120,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5a8d4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 4), (30,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape # 8:2 비율로 섞임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a912d092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 2, 1, 2, 2, 1, 0, 1, 1, 2, 0, 0, 0,\n",
       "        2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0,\n",
       "        1, 2, 1, 0, 1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 2, 2, 1, 0, 1, 0, 2, 2,\n",
       "        0, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0, 0, 1, 2, 2, 1, 1, 0, 2, 0, 0, 1,\n",
       "        1, 2, 0, 1, 1, 2, 2, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 1, 2,\n",
       "        0, 2, 1, 1, 0, 2, 1, 2, 1, 0]),\n",
       " array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2,\n",
       "        1, 2, 2, 2, 1, 1, 2, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test # 위와 다르게 무작위로 섞임(train_test_split()의 영향)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27226b",
   "metadata": {},
   "source": [
    "## 2) 첫 번째 머신러닝 모델 학습시키기\n",
    "- 머신러닝 \n",
    "    - 지도 학습: 정답이 있는 문제에 대해 학습하는 것\n",
    "         - 분류: 입력받은 데이터를 특정 카테고리 중 하나로 분류함\n",
    "         - 회귀: 입력받은 데이터에 따라 특정 필드의 수치를 맞춤\n",
    "    - 비지도 학습: 정답이 없는 문제를 학습하는 것\n",
    "    \n",
    "\n",
    "- __붓꽃 품종 문제는 지도학습인가, 비지도학습인가?__\n",
    "    - 지도학습. 붓꽃 품종에 대한 정답이 존재하기 때문\n",
    "        \n",
    "\n",
    "- __붓꽃 품종 문제는 분류 문제인가, 회귀 문제인가?__\n",
    "    - 분류 문제.세 가지 품종 중 하나로 분류하는 문제이기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab1482",
   "metadata": {},
   "source": [
    "- label이라는 정답지가 있으니 모델이 지도받을 수 있다. 즉, 붓꽃 품종 문제는 지도학습에 해당한다. \n",
    "\n",
    "- 붓꽃 품종 문제는 feature 데이터를 입력받으면 setosa, versicolor, virginica 세 가지 품종 중 하나로 분류해내는, 분류 문제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbf558",
   "metadata": {},
   "source": [
    "#### 분류와 회귀의 예시\n",
    "- 분류 : 환자의 나이, 병력, 혈당 등을 입력받아 암의 양성/음성을 판정하는 문제\n",
    "- 회귀 : 택시를 탄 시각, 내린 시각, 출발지, 도착지, 거리 등을 입력받아 택시 요금을 맞추는 문제. 집에 대한 정보(평수, 위치, 층수 등)를 입력받아 그 집의 가격을 맞추는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb53a32",
   "metadata": {},
   "source": [
    "### 정리해본다면,\n",
    "우리가 해결하고자 하는 붓꽃 문제:\n",
    "- 첫 번째, 머신러닝 중 정답이 있고 그 정답을 맞추기 위해 학습하는 지도 학습(Supervised Learning)이며,\n",
    "- 지도학습 중에서는 특정 카테고리 중 주어진 데이터가 어떤 카테고리에 해당하는지를 맞추는 분류(Classification) 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e8b03",
   "metadata": {},
   "source": [
    "__어떤 머신러닝 모델을 써야하는가?__\n",
    " - 지도학습 중에서도 분류를 할 수 있는 모델을 사용하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2f4ca",
   "metadata": {},
   "source": [
    "### 1. Decision Tree 모델\n",
    "- 직관적이면서도 간단하게 사용할 수 있음\n",
    "- 분류 문제를 풀 때 가장 기본적으로 쓰이는 모델 중 하나\n",
    "- 의사 결정을 할, 즉 데이터를 분리할 어떤 경계를 찾아내어 데이터를 체에 거르듯 한 단계씩 분류해나가는 모델\n",
    "- __필요 개념: 엔트로피, 정보량, 지니불순도 등의 정보이론 개념__\n",
    "\n",
    "\n",
    "- https://ratsgo.github.io/machine%20learning/2017/03/26/tree/\n",
    "\n",
    "\n",
    "- 의사결정트리:\n",
    "    - 데이터를 분리해나가는 모습이 나무를 뒤집어놓은 것과 같은 모양\n",
    "    - 단점: 결정경계가 데이터 축에 수직이어서 특정 데이터에만 잘 작동, 이를 극복하기 위해 제안된 모델이 Random Forest이며, 여러 개의 Decision Tree를 합쳐서 만들어놓은 개념"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15fd077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "print(decision_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e742d",
   "metadata": {},
   "source": [
    "- __keyword: fit()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4e52724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미 설계된 API구조이기에 바로 학습 시키기\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea650f80",
   "metadata": {},
   "source": [
    "- 매서드 fit()\n",
    "    - training dataset 으로 모델을 학습시킨다는 것은, 달리 말하면 training dataset에 맞게 모델을 fitting, 즉 맞추는 것이다.\n",
    "    - training dataset에 있는 데이터들을 통해 어떠한 패턴을 파악하고, 그 패턴에 맞게 예측을 할수 있도록 학습되기 때문이다.\n",
    "    - 면 모델은 training dataset에 존재하지 않는 데이터에 대해서는 정확한 정답 카테고리가 무엇인지 알지 못한다.\n",
    "    - training dataset을 통해 학습한 패턴으로 새로운 데이터가 어떤 카테고리에 속할지 예측할 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fb3f1",
   "metadata": {},
   "source": [
    "## 3) 첫 번째 머신러닝 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bf25d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 1, 2,\n",
       "       1, 1, 2, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터로 예측하기\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789974e",
   "metadata": {},
   "source": [
    "X_test 데이터에는 정답인 label이 없고 feature 데이터만 존재했다. 따라서 학습이 완료된 decision_tree 모델에 X_test 데이터로 predict 를 실행하면 모델이 예측한 y_pred를 얻게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "025a1904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2,\n",
       "       1, 2, 2, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 정답과 비교하기\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0b7e4",
   "metadata": {},
   "source": [
    "#### - 예측한 결과에 대한 수치를 조금 더 편리하게 확인할 수 있는 방법\n",
    "__정확도__ : 성능을 평가하는 방법의 척도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b154bc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy\n",
    "# 정확도 = 예측 결과가 정답인 데이터의 개수 / 예측한 전체 데이터의 개수\n",
    "# 즉, 전체 개수 중 맞은 것의 개수의 수치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1506936b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 30 * 0.9\n",
    "# 모델 30개 대해 예측한 것 중 맞은 게 27개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0936e4d",
   "metadata": {},
   "source": [
    "# 3. 다른 모델로 실습해보기_iris\n",
    "## 4) 다른 모델도 해 보고 싶다면? 코드 한 줄만 바꾸면 돼!\n",
    "편리하게 설계된 scikit-learn 덕분에 아주 간단하다. 익숙해지면 심지어 한 줄의 코드만 수정해도 된다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 다른 모델들을 다루기 전에 위에서 사용했던 Decision Tree 모델을 학습시키고 예측하는 과정 정리\n",
    "\n",
    "### (1) 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47c1382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf366159",
   "metadata": {},
   "source": [
    "### (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b83e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45de63",
   "metadata": {},
   "source": [
    "### (3) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10e502d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data,\n",
    "                                                    iris_label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02c43c",
   "metadata": {},
   "source": [
    "### (4) 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09415eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.91      0.91      0.91        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84efa6",
   "metadata": {},
   "source": [
    "### 여기서 모델을 바꿔보고 싶다면 (4) 모델 학습 및 예측 부분에서 모델만 바꿔주면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf40ce60",
   "metadata": {},
   "source": [
    "### 2. RandomForest\n",
    "-  Decision Tree 모델을 여러개 합쳐놓음으로써 Decision Tree의 단점을 극복한 모델\n",
    "-  앙상블(Ensemble) 기법: \n",
    "    - 단일 모델을 여러 개 사용하는 방법을 취함으로써 모델 한 개만 사용할 때의 단점을 집단지성으로 극복하는 개념이다.\n",
    "    \n",
    "    \n",
    "- https://medium.com/@deepvalidation/title-3b0e263605de\n",
    "\n",
    "\n",
    "-  Random Forest는 여러개의 의사 결정 트리를 모아 놓은것으로, 각각의 의사 결정 트리를 만들기 위해 쓰이는 특성들을 랜덤으로 선택한다.\n",
    "- 이는 상위 모델들이 예측하는 편향된 결과보다, 다양한 모델들의 결과를 반영함으로써 더 다양한 데이터에 대한 의사결정을 내릴 수 있게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89f7eab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data,\n",
    "                                                    iris_label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=25)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e84cac",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machine (SVM)\n",
    "- https://excelsior-cjh.tistory.com/66?category=918734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4a663dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "# 학습시키고\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 결과 확인\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7cf23",
   "metadata": {},
   "source": [
    "### 4. Stochastic Gradient Descent Classifier (SGDClassifier)\n",
    "- https://scikit-learn.org/stable/modules/sgd.html\n",
    "- (링크 안됨)https://datascienceschool.net/view-notebook/342b8e2ecf7a4911a727e6fe97f4ab6b/\n",
    "- https://everyday-deeplearning.tistory.com/entry/SGD-Stochastic-Gradient-Descent-%ED%99%95%EB%A5%A0%EC%A0%81-%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95\n",
    "- https://developers.google.com/machine-learning/crash-course/reducing-loss/stochastic-gradient-descent?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e71f6237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95         9\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.40      1.00      0.57         8\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.43      0.67      0.51        30\n",
      "weighted avg       0.38      0.57      0.44        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\py3_7_6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\py3_7_6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\envs\\py3_7_6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ba1e3",
   "metadata": {},
   "source": [
    "### 5. Logistic Regression\n",
    "- http://hleecaster.com/ml-logistic-regression-concept/\n",
    "-  회귀를 사용하여 데이터가 어떠한 범주에 속할 확률을 0에서 1 사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도학습 알고리즘\n",
    "- 예) 스팸 메일 분류기,  데이터가 2개의 범주(ex. 스팸인지 아닌지) 중 하나에 속하도록 결정하는 것을 2진 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78f14603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\py3_7_6\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "print(logistic_model._estimator_type)\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1ba64",
   "metadata": {},
   "source": [
    "# 4 오차행렬_iris\n",
    "## 4) 내 모델은 얼마나 똑똑한가? 다양하게 평가해보기\n",
    "머신러닝에서는 모델을 학습시키는 것뿐만 아니라 그 성능을 정확히 평가하고 개선하는 것이 매우 중요하다. 모델의 성능을 평가하는 데에는 정확도뿐만 아니라 다른 척도들이 존재한다.\n",
    "\n",
    "### (1) 정확도에는 함정이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c886440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits() # digit에 손글씨 데이터 저장\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5b151b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "digits_data.shape # 총 1797개가 있고, 각 데이터는 64개의 숫자로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd757587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 확인\n",
    "digits_data[0] #64개의 숫자로 이루어진 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9b2c1",
   "metadata": {},
   "source": [
    "손글씨 데이터는 이미지 데이터이다. 따라서 각 숫자는 픽셀값을 의미하며, 길이 64의 숫자 배열은 사실 8 x 8 크기의 이미지를 일렬로 쭉 펴놓은 것을 의미한다.\n",
    "\n",
    "\n",
    "이미지는 다음과 같이 간단히 확인할 수 있다. 다만, 일렬로 펴진 64개 데이터를 (8, 8)로 reshape 해줘야 한다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16de2b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "756164e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 여려 개 이미지 확인해보기 \n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba6b9861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타깃 데이터는? \n",
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "digits_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a70e40",
   "metadata": {},
   "source": [
    "- 우리의 문제는:\n",
    "    - 붓꽃 문제와 같이, 각 이미지 데이터가 입력되었을 때 그 이미지가 숫자 몇을 나타내는 이미지인지를 맞추는 분류 모델을 학습시키면 된다.\n",
    "\n",
    "\n",
    "- 다만 정확도의 함정을 알아보는 문제이므로,\n",
    "    - 숫자 10개를 모두 분류하는 것이 아니라, 해당 이미지 데이터가 3인지 아닌지를 맞추는문제로 변형해서 풀어볼 것이다.\n",
    "    - 입력된 데이터가 3이라면 3을, 3이 아닌 다른 숫자라면 0을 출력하도록 하는 모델로 말이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6bace1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label = [3 if i == 3 else 0 for i in digits_label]\n",
    "new_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7222d",
   "metadata": {},
   "source": [
    "##### 문제: digits_data와 new_label로 Decision Tree 모델을 학습시키고, 정확도를 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac0f2fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       326\n",
      "           3       0.77      0.88      0.82        34\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.88      0.93      0.90       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                    new_label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=7)\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f966f3",
   "metadata": {},
   "source": [
    "##### 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "670c9273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388888888888889"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                    new_label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=15)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=15)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea6b28",
   "metadata": {},
   "source": [
    "우리는 총 10개의 숫자 중 3에만 집중을 해서, 3이라면 3으로, 3이 아니라면 0으로 맞추는 문제로 변형했었다. 그런 이유로, 정답 데이터인 label은 0이 굉장히 많고 3은 적은 불균형 데이터가 되었다. 9개의 숫자들은 label이 모두 0이 되었고, 3만 3으로 남아있었으니 대략 90%의 label이 모두 0이라는 소리다.\n",
    "\n",
    "\n",
    "__모델이 전혀 학습하지 않고 정답을 모두 0으로만 선택해도 정확도가 90%가량이 나오게 된다는 것!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "831a6b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 길이는 y_pred 와 같으면서 0 으로만 이루어진 리스트\n",
    "fake_pred = [0] * len(y_pred)\n",
    "accuracy = accuracy_score(y_test, fake_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44001a",
   "metadata": {},
   "source": [
    "- 이러한 문제는 불균형한 데이터, unbalanced 데이터에서 많이 발생할 수 있다.\n",
    "- 정확도는 정답의 분포에 따라 모델의 성능을 잘 평가하지 못하는 척도가 될 수 있는 것이다.\n",
    "- 그렇기에 분류 문제에서는 정확도 외에 다양한 평가 척도를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485e556",
   "metadata": {},
   "source": [
    "### (2) 정답과 오답에도 종류가 있다!\n",
    "-  정확도는 전체 데이터 중 맞은 데이터 만 신경쓰는 척도이다.\n",
    "- 얼마나 많은 양성 데이터를 맞았느냐도 중요하겠지만, 음성 데이터를 얼마나 안 틀렸느냐도 중요한 경우가 있다.\n",
    "\n",
    "\n",
    "-  같은 오진이라도 양성을 잡아내는 데에 실패하는 오진과, 음성을 잡아내는 데에 실패하는 오진은 그 중요도가 다를 수 있다.\n",
    "- __오차행렬(confusion matrix): 정답과 오답을 구분하여 표현하는 방법__\n",
    "- https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dcf9e8",
   "metadata": {},
   "source": [
    "- 실제 클래스(Actual Class)\n",
    "    - Actual Class가 Positive라면 환자는 실제 코로나에 걸린 것\n",
    "    - 반대로 Actual Class가 Negative라면 환자는 건강함\n",
    "- 예측된 클래스(Predicted Class)\n",
    "    - Predicted Class가 Positive라면 진단 결과가 양성\n",
    "    - Negative라면 진단 결과가 음성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7d8bc",
   "metadata": {},
   "source": [
    "- TP(True Positive) : 실제 환자에게 양성판정 (참 양성)\n",
    "- FN(False Negative) : 실제 환자에게 음성판정 (거짓 음성)\n",
    "- FP(False Positive) : 건강한 사람에게 양성판정 (거짓 양성)\n",
    "- TN(True Negative) : 건강한 사람에게 음성판정 (참 음성)\n",
    "\n",
    "\n",
    "- TP, FN, FP, TN의 수치로 계산되는 성능 지표 중 대표적으로 쓰이는 것은 __정밀도(Precision), 재현율(Recall, Sensitivity), F1 스코어(f1 score)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf342db",
   "metadata": {},
   "source": [
    "#### # 공식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea1c6b",
   "metadata": {},
   "source": [
    "- 정밀도(Precision) : TP / FP+TP\n",
    "\n",
    "\n",
    "- 재현율(Recall, Sensitivity) : TP / FN+TP\n",
    "\n",
    "\n",
    "- F1 스코어(f1 score) : 2 / ((1/Recall)+(1/Precision))\n",
    "\n",
    "\n",
    "- 정확도(Accuracy) : TP + TN / TP + TN + FP + FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8163ff8",
   "metadata": {},
   "source": [
    "1) \n",
    "- Precision과 Recall의 분자는 둘 다 TP다. TP는 맞게 판단한 양성이므로, 이 값은 높을수록 좋다.\n",
    "- 분모에는 각각 FP와 FN가 있다. 이 값들은 잘못 판단된 것들이므로 낮을수록 좋다.\n",
    "- 즉, TP는 높고 FP또는 FN이 낮을수록 좋은 예측이므로, Precision과 Recall 값이 클수록 좋다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3a4d1",
   "metadata": {},
   "source": [
    "2)\n",
    "- Precision은 분모에 있는 FP가 낮을수록 커진다. Precision이 높아지려면 False Positive, 즉 음성인데 양성으로 판단하는 경우가 적어야 한다.\n",
    "- Recall은 분모에 있는 FN이 낮을수록 커진다. Recall이 높아지려면 False Negative, 즉 양성인데 음성으로 판단하는 경우가 적어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0bbc39",
   "metadata": {},
   "source": [
    "#### 다시 생각해보자\n",
    "- Precision이 크려면 음성인데 양성으로 판단하는 경우가 적어야 한다. 음성을 놓치지 말아야 한다건데, 어떤 경우일까?\n",
    "    - 메일 처리 모델은 스팸 메일을 못 거르는 것은 괜찮지만, 정상 메일을 스팸 메일로 분류하는 것은 더 큰 문제입니다. 즉, 음성을 양성으로 판단하면 안된다. 따라서 Precision이 더 중요하다.\n",
    "\n",
    "\n",
    "- Recall이 크려면 양성인데 음성으로 판단하는 경우가 적어야 한다. 양성을 놓치지 말아야 하는데 어떤 경우가 있을까?\n",
    "    - 암을 진단하는 경우 실제 환자를 한 명이라도 놓치면 안된다. 즉, 양성을 음성으로 판단하면 안 되기 때문에 Recall이 더 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37d7fdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[320,  13],\n",
       "       [  9,  18]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# 왼쪽 위부터 순서대로 TP, FN, FP, TN의 개수\n",
    "# 손글씨 문제에서의 `0`은 Positive 역할을, `3`은 Negative 역할\n",
    "# TP와 TN의 값이 320, 18로 비교적 크고 FN과 FP는 13, 9로 작다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16357456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[333,   0],\n",
       "       [ 27,   0]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 숫자를 0으로 예측한 fake_pred는?\n",
    "confusion_matrix(y_test, fake_pred)\n",
    "#  Positive로 예측했고 Negative로 예측한 것은 없기 때문에 FN과 TN은 둘다 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5561f1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       333\n",
      "           3       0.58      0.67      0.62        27\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.78      0.81      0.79       360\n",
      "weighted avg       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이런 경우 Precision, Recall, f1 score는 각각 얼마가 될까?\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d3377",
   "metadata": {},
   "source": [
    "0 에 대한 precision과 recall은 0.93, 1로 매우 높지만 3 에 대한 precision과 recall은 둘 다 0이라는 것은, 0 은 잘 잡아내지만, 3 은 단 하나도 맞추지 못했다는 뜻이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f435f9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9388888888888889, 0.925)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred), accuracy_score(y_test, fake_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f356a",
   "metadata": {},
   "source": [
    "### 결론\n",
    "- 모델의 성능은 정확도만으로 평가하면 안된다! 특히, label이 불균형하게 분포되어있는 데이터를 다룰 때에는 더 조심해야 한다.\n",
    "- Precision과 Recall이 각각 언제 중요해지는지를 이해하고, 때에 맞는 성능지표로 모델을 평가를 해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908ac54",
   "metadata": {},
   "source": [
    "- 평가 부분에서 이해 봅기 위한 블로그\n",
    "https://shate-programming.tistory.com/28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5719f5b1",
   "metadata": {},
   "source": [
    "1) precision(정밀도): 어떠한 클래스(예시: 클래스 A)로 분류한 데이터 중 실제로 클래스 A일 비율 (높을수록 좋다.)\n",
    "\n",
    ">> 즉, 정밀도는 예측한 데이터 셋 중 얼마나 실제와 일치하는 지 보는 것\n",
    "\n",
    "2) recall(재현율): 실제 클래스 A에 속한 데이터 중 클래스 A로 예측한 표본의 수 비율 (높을수록 좋다.)\n",
    "\n",
    ">> 즉, 재현율은 실제 데이터 셋 중 여러 개의 데이터에 대해 하나의 클래스로 잘 분류할 수 있는 지 보는 것\n",
    "\n",
    "3) F-Score: 정밀도와 재현율의 가중조화평균으로 구한다. 공식은 아래와 같다. 모델의 평균적인 성능 비교 시 유용\n",
    "\n",
    "F1-score = (2precisionrecall) / (precision + recall)\n",
    "\n",
    "4) accuracy(정확도): 전체 샘플 중 올바르게 예측한 샘플 수의 비율 (높을수록 좋다.) 하지만 데이터 편향되어 있다면 유용하지 않을 수 있다.\n",
    "\n",
    "_다중 클래스 분류_의 경우 각각의 클래스에 대해 자신을 양성 클래스, 다른 클래스를 음성 클래스로 가정하는데 각 클래스별로 구한 정밀도, 재현율, F1-score의 평균 점수를 구해야 한다.\n",
    "\n",
    "5) macro avg: 단순 평균\n",
    "\n",
    "6) weighted avg: 각 클래스에 속하는 표본의 갯수로 가중평균\n",
    "\n",
    "http://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61401642",
   "metadata": {},
   "source": [
    "--- seYi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_7_6",
   "language": "python",
   "name": "py3_7_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
